{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model and load weights\n",
      "Model ready\n",
      "Globbed 1024 wav files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:34<00:00, 29.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from vqvae import VQVAE\n",
    "import librosa\n",
    "from librosa.util import normalize\n",
    "\n",
    "with open('./config_24k_320d.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    sample_rate = config['sampling_rate']\n",
    "\n",
    "outputdir = '../outputdir'\n",
    "inputdir = '../test-other'\n",
    "num = 1024\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Path(outputdir).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Init model and load weights\")\n",
    "    # make sure you download the weights from https://huggingface.co/Dongchao/AcademiCodec/blob/main/HiFi-Codec-24k-320d and put it in ../ckpt/\n",
    "    model = VQVAE('./config_24k_320d.json', '../ckpt/HiFi-Codec-24k-320d', with_encoder=True, return_acoustic_tokens_only=True)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    print(\"Model ready\")\n",
    "    \n",
    "    wav_paths = glob.glob(f\"{inputdir}/**/**/*.wav\")[:num]\n",
    "    print(f\"Globbed {len(wav_paths)} wav files.\")\n",
    "    fid_to_acoustic_token = {}\n",
    "    for wav_path in tqdm(wav_paths):\n",
    "        wav, sr = sf.read(wav_path)\n",
    "        if sr != sample_rate:\n",
    "            wav = librosa.resample(wav, orig_sr=sr, target_sr=sample_rate)\n",
    "        fid = os.path.basename(wav_path)[:-4]\n",
    "        wav = normalize(wav) * 0.95\n",
    "        wav = torch.FloatTensor(wav).unsqueeze(0)\n",
    "        wav = wav.to(torch.device('cuda'))\n",
    "        vq_codes = model.encode(wav) # \n",
    "        acoustic_token = model(vq_codes)\n",
    "        fid = os.path.basename(wav_path)[:-4]\n",
    "        fid_to_acoustic_token[fid] = acoustic_token\n",
    "    \n",
    "    torch.save(fid_to_acoustic_token, outputdir + '/fid_to_acoustic_token.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLAS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
